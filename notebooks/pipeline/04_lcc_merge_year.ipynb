{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4004123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Written full enriched 2024 dataset to:\n",
      "  /Users/jakobschneider/Machine Learning/Data_LCC/Data_merged.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# ---------- 0. Patterns anpassen ----------\n",
    "LOGS_PATTERN = '/Users/jakobschneider/Machine Learning/Data_LCC/2024_NOAA_AIS_logs_*.parquet'\n",
    "SHIPS_PATTERN = '/Users/jakobschneider/Machine Learning/Data_LCC/2024_NOAA_AIS_ships_*.parquet'\n",
    "\n",
    "OUTPUT_YEAR = '/Users/jakobschneider/Machine Learning/Data_LCC/Data_merged.parquet'\n",
    "\n",
    "\n",
    "# ---------- 1. Lazy scans ----------\n",
    "logs_all = pl.scan_parquet(LOGS_PATTERN)\n",
    "ships_all = pl.scan_parquet(SHIPS_PATTERN)\n",
    "\n",
    "\n",
    "# ---------- 2. Cast BaseDateTime to Datetime ----------\n",
    "logs_all = logs_all.with_columns(\n",
    "    pl.col(\"BaseDateTime\").cast(pl.Datetime)\n",
    ")\n",
    "\n",
    "ships_all = (\n",
    "    ships_all\n",
    "    .with_columns(\n",
    "        pl.col(\"BaseDateTime\").cast(pl.Datetime)\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"BaseDateTime\").alias(\"ShipMetadataTimestamp\")\n",
    "    )\n",
    "    .drop(\"BaseDateTime\")\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- 3. Drop ALL rows in logs with ANY missing values ----------\n",
    "# This removes rows where ANY column (MMSI, LAT, LON, SOG, COG, Heading, Status, BaseDateTime)\n",
    "# is null or NaN.\n",
    "logs_clean = logs_all.drop_nulls()\n",
    "\n",
    "\n",
    "# ---------- 4. Ships: reduce columns ----------\n",
    "ships_reduced = ships_all.select([\n",
    "    \"MMSI\",\n",
    "    \"VesselName\",\n",
    "    \"IMO\",\n",
    "    \"CallSign\",\n",
    "    \"VesselType\",\n",
    "    \"Length\",\n",
    "    \"Width\",\n",
    "    \"Draft\",\n",
    "    \"Cargo\",\n",
    "    \"TransceiverClass\",\n",
    "    \"ShipMetadataTimestamp\",\n",
    "]).unique(\"MMSI\", keep=\"last\")  # ensure 1x per MMSI\n",
    "\n",
    "\n",
    "# ---------- 5. Join logs + ships via MMSI ----------\n",
    "logs_enriched = (\n",
    "    logs_clean.join(\n",
    "        ships_reduced,\n",
    "        on=\"MMSI\",\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- 6. Optional relevant ship filter ----------\n",
    "# You can comment this out if you want the full dataset.\n",
    "relevant_vessel_types = [70, 71, 72, 73, 74, 75, 76]  # example only\n",
    "\n",
    "logs_filtered = (\n",
    "    logs_enriched\n",
    "    .filter(\n",
    "        (pl.col(\"TransceiverClass\") == \"A\") &\n",
    "        (pl.col(\"Draft\") > 0) &\n",
    "        (pl.col(\"VesselType\").is_in(relevant_vessel_types))\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# ---------- 7. Write final annual parquet ----------\n",
    "logs_filtered.sink_parquet(OUTPUT_YEAR)\n",
    "\n",
    "print(f\"\\nWritten full enriched 2024 dataset to:\\n  {OUTPUT_YEAR}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b05e7",
   "metadata": {},
   "source": [
    "Neue Jahresdatei nur mit Transceiverklasse A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1facdffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefilterte Datei geschrieben nach: /Users/jakobschneider/Machine Learning/Data_LCC/AIS_2024_enriched_classA.parquet\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "PATH_YEAR = '/Users/jakobschneider/Machine Learning/Data_LCC/Data_merged.parquet'\n",
    "\n",
    "PATH_YEAR_A = \"/Users/jakobschneider/Machine Learning/Data_LCC/AIS_2024_enriched_classA.parquet\"\n",
    "\n",
    "lf = pl.scan_parquet(PATH_YEAR)\n",
    "\n",
    "# Nur TransceiverClass A behalten\n",
    "lf_class_a = lf.filter(pl.col(\"TransceiverClass\") == \"A\")\n",
    "\n",
    "# Direkt als neue Parquet-Datei schreiben (Lazy → kein vollständiges collect im RAM)\n",
    "lf_class_a.sink_parquet(PATH_YEAR_A)\n",
    "\n",
    "print(f\"Gefilterte Datei geschrieben nach: {PATH_YEAR_A}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c4d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/68z2fm6j28jfpyn0vqv3j9fw0000gn/T/ipykernel_9886/1026585312.py:7: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  row_count = lf_a.select(pl.count()).collect()[0, 0]\n",
      "/var/folders/s6/68z2fm6j28jfpyn0vqv3j9fw0000gn/T/ipykernel_9886/1026585312.py:11: PerformanceWarning: Resolving the schema of a LazyFrame is a potentially expensive operation. Use `LazyFrame.collect_schema()` to get the schema without this warning.\n",
      "  print(\"Columns:\", len(lf_a.schema))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows (class A): 225298554\n",
      "Columns: 18\n",
      "shape: (1, 2)\n",
      "┌────────────┬─────────────┐\n",
      "│ unique_imo ┆ unique_mmsi │\n",
      "│ ---        ┆ ---         │\n",
      "│ u32        ┆ u32         │\n",
      "╞════════════╪═════════════╡\n",
      "│ 8491       ┆ 8693        │\n",
      "└────────────┴─────────────┘\n",
      "shape: (20, 18)\n",
      "┌───────────┬──────────────┬──────────┬────────────┬───┬───────┬───────┬─────────────┬─────────────┐\n",
      "│ MMSI      ┆ BaseDateTime ┆ LAT      ┆ LON        ┆ … ┆ Draft ┆ Cargo ┆ Transceiver ┆ ShipMetadat │\n",
      "│ ---       ┆ ---          ┆ ---      ┆ ---        ┆   ┆ ---   ┆ ---   ┆ Class       ┆ aTimestamp  │\n",
      "│ i64       ┆ datetime[μs] ┆ f64      ┆ f64        ┆   ┆ f64   ┆ f64   ┆ ---         ┆ ---         │\n",
      "│           ┆              ┆          ┆            ┆   ┆       ┆       ┆ str         ┆ datetime[μs │\n",
      "│           ┆              ┆          ┆            ┆   ┆       ┆       ┆             ┆ ]           │\n",
      "╞═══════════╪══════════════╪══════════╪════════════╪═══╪═══════╪═══════╪═════════════╪═════════════╡\n",
      "│ 314510000 ┆ 2024-01-01   ┆ 29.89929 ┆ -89.90665  ┆ … ┆ 7.1   ┆ 70.0  ┆ A           ┆ 2024-10-01  │\n",
      "│           ┆ 00:00:00     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 00:00:34    │\n",
      "│ 367468270 ┆ 2024-01-01   ┆ 30.42718 ┆ -89.05528  ┆ … ┆ 3.0   ┆ 70.0  ┆ A           ┆ 2024-12-01  │\n",
      "│           ┆ 00:00:00     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 18:24:08    │\n",
      "│ 413173000 ┆ 2024-01-01   ┆ 28.89991 ┆ -94.22794  ┆ … ┆ 11.9  ┆ 71.0  ┆ A           ┆ 2024-03-03  │\n",
      "│           ┆ 00:00:00     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 10:38:33    │\n",
      "│ 563169400 ┆ 2024-01-01   ┆ 30.38482 ┆ -81.05639  ┆ … ┆ 9.8   ┆ 74.0  ┆ A           ┆ 2024-01-01  │\n",
      "│           ┆ 00:00:01     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 00:00:01    │\n",
      "│ 563207600 ┆ 2024-01-01   ┆ 35.23035 ┆ -121.32948 ┆ … ┆ 8.2   ┆ 70.0  ┆ A           ┆ 2024-12-12  │\n",
      "│           ┆ 00:00:01     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 05:20:23    │\n",
      "│ …         ┆ …            ┆ …        ┆ …          ┆ … ┆ …     ┆ …     ┆ …           ┆ …           │\n",
      "│ 366930730 ┆ 2024-01-01   ┆ 47.01493 ┆ -91.6714   ┆ … ┆ 7.8   ┆ 70.0  ┆ A           ┆ 2024-12-01  │\n",
      "│           ┆ 00:00:03     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 00:00:03    │\n",
      "│ 366971370 ┆ 2024-01-01   ┆ 47.3862  ┆ -86.73686  ┆ … ┆ 7.3   ┆ 70.0  ┆ A           ┆ 2024-12-01  │\n",
      "│           ┆ 00:00:04     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 00:00:05    │\n",
      "│ 636018222 ┆ 2024-01-01   ┆ 37.77835 ┆ -122.58878 ┆ … ┆ 10.8  ┆ 72.0  ┆ A           ┆ 2024-12-08  │\n",
      "│           ┆ 00:00:04     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 11:50:17    │\n",
      "│ 636090636 ┆ 2024-01-01   ┆ 18.1025  ┆ -68.3059   ┆ … ┆ 8.9   ┆ 70.0  ┆ A           ┆ 2024-01-01  │\n",
      "│           ┆ 00:00:04     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 00:00:04    │\n",
      "│ 353821000 ┆ 2024-01-01   ┆ 49.321   ┆ -123.16493 ┆ … ┆ 13.3  ┆ 70.0  ┆ A           ┆ 2024-11-01  │\n",
      "│           ┆ 00:00:05     ┆          ┆            ┆   ┆       ┆       ┆             ┆ 00:00:09    │\n",
      "└───────────┴──────────────┴──────────┴────────────┴───┴───────┴───────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "PATH_YEAR_A = \"/Users/jakobschneider/Machine Learning/Data_LCC/AIS_2024_enriched_classA.parquet\"\n",
    "lf_a = pl.scan_parquet(PATH_YEAR_A)\n",
    "\n",
    "# Zeilenanzahl (ohne alles zu laden)\n",
    "row_count = lf_a.select(pl.count()).collect()[0, 0]\n",
    "print(\"Rows (class A):\", row_count)\n",
    "\n",
    "# Anzahl Spalten\n",
    "print(\"Columns:\", len(lf_a.schema))\n",
    "\n",
    "# Distinct IMO / MMSI\n",
    "print(\n",
    "    lf_a.select([\n",
    "        pl.col(\"IMO\").n_unique().alias(\"unique_imo\"),\n",
    "        pl.col(\"MMSI\").n_unique().alias(\"unique_mmsi\"),\n",
    "    ]).collect()\n",
    ")\n",
    "\n",
    "# Ein paar Zeilen anschauen (das ist safe)\n",
    "print(lf_a.limit(20).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ad6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop MMSI\n",
    "lf = pl.scan_parquet(\"/Users/jakobschneider/Machine Learning/Data_LCC/AIS_2024_enriched_classA.parquet\")\n",
    "\n",
    "lf_no_mmsi = lf.drop(\"MMSI\")\n",
    "\n",
    "lf_no_mmsi.sink_parquet(\"/Users/jakobschneider/Machine Learning/Data_LCC/AIS_2024_enriched_classA_noMMSI.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82a43d",
   "metadata": {},
   "source": [
    "Zielvariable hinzufügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6afa0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakobschneider/Machine Learning/.venv311/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRV columns: ['Ship', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Company', 'Unnamed: 9', 'DoC', 'Unnamed: 11', 'Verifier', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Monitoring methods', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Annual monitoring results', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50', 'Unnamed: 51', 'Unnamed: 52', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 55', 'Unnamed: 56', 'Unnamed: 57', 'Unnamed: 58', 'Unnamed: 59', 'Unnamed: 60', 'Unnamed: 61', 'Unnamed: 62', 'Unnamed: 63', 'Unnamed: 64', 'Unnamed: 65', 'Unnamed: 66', 'Unnamed: 67', 'Unnamed: 68', 'Unnamed: 69', 'Unnamed: 70', 'Unnamed: 71', 'Unnamed: 72', 'Unnamed: 73', 'Unnamed: 74', 'Unnamed: 75', 'Unnamed: 76', 'Unnamed: 77', 'Unnamed: 78', 'Unnamed: 79', 'Unnamed: 80', 'Unnamed: 81', 'Unnamed: 82', 'Unnamed: 83', 'Unnamed: 84', 'Unnamed: 85', 'Unnamed: 86', 'Unnamed: 87', 'Unnamed: 88', 'Unnamed: 89', 'Unnamed: 90', 'Unnamed: 91', 'Unnamed: 92', 'Unnamed: 93', 'Unnamed: 94', 'Unnamed: 95', 'Unnamed: 96', 'Unnamed: 97', 'Unnamed: 98', 'Unnamed: 99', 'Unnamed: 100', 'Unnamed: 101', 'Unnamed: 102', 'Unnamed: 103', 'Unnamed: 104', 'Unnamed: 105', 'Unnamed: 106', 'Unnamed: 107', 'Unnamed: 108', 'Unnamed: 109', 'Unnamed: 110', 'Unnamed: 111', 'Unnamed: 112']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['IMO', 'Total CO₂eq emissions [m tonnes]'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMRV columns:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(mrv_pd.columns))\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Keep only IMO and emissions column\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m mrv_pd = \u001b[43mmrv_pd\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIMO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMRV_EMISS_COL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# ----------------- 3) Convert MRV to Polars -----------------\u001b[39;00m\n\u001b[32m     29\u001b[39m mrv = pl.from_pandas(mrv_pd)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Machine Learning/.venv311/lib/python3.11/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Machine Learning/.venv311/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Machine Learning/.venv311/lib/python3.11/site-packages/pandas/core/indexes/base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['IMO', 'Total CO₂eq emissions [m tonnes]'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------- Paths (adjust if needed) -----------------\n",
    "AIS_PATH = \"/Users/jakobschneider/Machine Learning/Data_LCC/AIS_2024_enriched_classA_noMMSI.parquet\"\n",
    "MRV_PATH = \"/Users/jakobschneider/Machine Learning/Data_LCC/MRV_2024.xlsx\"\n",
    "OUTPUT_PATH = \"/Users/jakobschneider/Machine Learning/Data_LCC/AIS_2024_classA_MRV.parquet\"\n",
    "\n",
    "# Name of the MRV emissions column (adjust if the name differs slightly)\n",
    "MRV_EMISS_COL = \"Total CO₂eq emissions [m tonnes]\"  # column BG in Excel\n",
    "\n",
    "\n",
    "# ----------------- 1) Load AIS (lazy) -----------------\n",
    "# AIS is large, so we use scan_parquet to avoid loading everything into RAM at once\n",
    "ais_lf = pl.scan_parquet(AIS_PATH)\n",
    "\n",
    "\n",
    "# ----------------- 2) Load MRV Excel via pandas -----------------\n",
    "# MRV is small (~35k rows), pandas in memory is fine\n",
    "mrv_pd = pd.read_excel(MRV_PATH)\n",
    "\n",
    "# Optional: print columns once to verify the exact column names\n",
    "print(\"MRV columns:\", list(mrv_pd.columns))\n",
    "\n",
    "# Keep only IMO and emissions column\n",
    "mrv_pd = mrv_pd[[\"IMO\", MRV_EMISS_COL]].copy()\n",
    "\n",
    "# ----------------- 3) Convert MRV to Polars -----------------\n",
    "mrv = pl.from_pandas(mrv_pd)\n",
    "\n",
    "# Normalize column types: ensure IMO is same type in both datasets\n",
    "# We cast IMO to Utf8 in both to be safe.\n",
    "mrv = mrv.with_columns(\n",
    "    pl.col(\"IMO\").cast(pl.Utf8)\n",
    ").rename({MRV_EMISS_COL: \"Total_CO2eq_mt\"})  # easier column name\n",
    "\n",
    "ais_lf = ais_lf.with_columns(\n",
    "    pl.col(\"IMO\").cast(pl.Utf8)\n",
    ")\n",
    "\n",
    "\n",
    "# ----------------- 4) Join AIS + MRV on IMO -----------------\n",
    "# Left join: keep all AIS rows, add MRV emissions where available\n",
    "ais_with_mrv = ais_lf.join(\n",
    "    mrv,\n",
    "    on=\"IMO\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# ----------------- 5) Write result as Parquet -----------------\n",
    "# This triggers the lazy computation but streams the result to disk\n",
    "ais_with_mrv.sink_parquet(OUTPUT_PATH)\n",
    "\n",
    "print(f\"Written AIS + MRV merged dataset to:\\n  {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25ae6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
